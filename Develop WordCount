/*
spark-shell --master yarn \
  --conf spark.ui.port=12456 \
  --num-executors 10 \
  --executor-memory 3G \
  --executor-cores 2 \
  --packages com.databricks:spark-avro_2.10:2.0.1
*/

val lines = sc.textFile("/public/randomtextwriter")
val word = lines.flatMap(line => line.split(","))
val tuple = word.map(word => (word,1))
val wordcount = tuple.reduceByKey((total,value) => total + value,8)
val wordcountDF = wordcount.toDF("word","count")

import com.databricks.spark.avro._
wordcountDF.write.avro("/user/sumitsinha1680/solutions/solution05/wordcount")

